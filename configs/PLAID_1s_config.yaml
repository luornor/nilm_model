# Configuration for David_Data 1s-binned training

experiment_name: "david_1s_experiment"
output_dir: "outputs/david_training"

# Data configuration
data:
  dataset_root: "Dataset"
  matlab_data_dir: "Matlab_Data"
  exports_dir: "Exports"
  bin_size_seconds: 1.0       # Our david_train_1s.csv uses 1-second bins
  window_size: 5              # 5-second context over 1s bins
  normalize_per_window: true
  # David_Data is small per appliance, so use smaller thresholds
  min_samples_per_appliance: 20
  min_positives_per_appliance: 5

# Model configuration
model:
  name: "ImprovedSeq2PointCNN"
  window_size: 5
  input_channels: 1
  conv_channels: [32, 64, 128, 64]
  conv_kernel_size: 3
  conv_padding: 1
  hidden_dim: 64
  output_dim: 1
  activation: "relu"
  dropout: 0.3
  use_batch_norm: true
  use_residual: false

# Training configuration
training:
  batch_size: 128             # Slightly smaller for safety
  learning_rate: 0.001
  epochs: 30
  seed: 42
  loss_type: "BCEWithLogitsLoss"
  pos_weight_auto: true
  optimizer: "Adam"
  optimizer_kwargs: {}
  scheduler: "ReduceLROnPlateau"
  scheduler_patience: 3
  scheduler_factor: 0.5
  scheduler_step_size: 10
  scheduler_gamma: 0.1
  val_split: 0.2
  stratify: true
  log_interval: 100
  save_best: true
  device: null

# Fine-tuning configuration (unused for now)
fine_tuning:
  predictions_csv: ""
  pos_threshold: 0.90
  neg_threshold: 0.10
  max_pos_samples: 6000
  max_neg_samples: 6000
  min_confident_samples: 200
  epochs: 5
  learning_rate: 0.0002
  batch_size: 256
  use_fallback_selection: true

# Inference configuration (placeholder)
inference:
  natural_data_csv: ""
  model_dir: ""
  output_csv: ""
  target_appliances: []
  smoothing_window: 5
  on_threshold: 0.55
  off_threshold: 0.45
  plot_histograms: true
  plot_onoff_states: true
  plot_overlay: true
  plot_output_dir: ""

# Train all discovered appliances by default
target_appliances: null
